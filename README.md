# RAG-motorn ğŸš€

**Svenskt RAG-system (Retrieval-Augmented Generation) med hybrid retrieval, disk-cache och vÃ¤rldsklass kvalitetsmÃ¤tning.**

## ğŸ“‹ Ã–versikt

Ett produktionsklart RAG-system byggt fÃ¶r svenska, dokumenttunga kÃ¤llor med fokus pÃ¥:

- **HÃ¶g precision** â€“ Hybrid retrieval (BM25 + embeddings)  
- **Bra latens** â€“ Disk-cache med MTIME-guards, p95 < 2s  
- **Rimliga kostnader** â€“ Smart caching, batch-embeddings  
- **KvalitetsmÃ¤tning** â€“ Golden tests med tier-ranking (Diamond â†’ Bronze)

---

## âœ¨ Features

âœ… **Ingest & indexering**

- Multi-format: TXT, MD, PDF, DOCX  
- Smart chunking (ca 600 tokens, 120 overlap)  
- Batch-embeddings via OpenAI `text-embedding-3-large`  
- SQLite-persistens med versionshantering och mtime

âœ… **Hybrid retrieval**

- BM25 (exakta termer, namn, siffror)  
- Embeddings (semantisk likhet, parafraser)  
- Konfigurerbar viktning (`alpha=0.35`, `beta=0.65`)  
- Workspace- & document-filtrering (multi-tenant-stÃ¶d)

âœ… **Disk-cache med MTIME-guards**

- Instant startup (0 embeddings vid ofÃ¶rÃ¤ndrade dokument)  
- Auto-rebuild endast vid Ã¤ndrade filer  
- Cache per workspace: `./index_cache/{workspace}/`

âœ… **LLM-integration**

- OpenAI GPT-4o (Q&A), GPT-4o-mini (summary/extract)  
- Svenska prompter med kÃ¤llhÃ¤nvisningar  
- `temperature=0.0` fÃ¶r deterministiska svar

âœ… **Kvalitet & testing**

- Golden evaluation med tier-system (Diamond / Platinum / Gold / Silver / Bronze)  
- Performance-tester (p50 / p95 / p99-latens)  
- Stress-test (t.ex. 500+ queries)  
- Quality gates fÃ¶r CI/CD (blockera deploy vid fÃ¶r lÃ¥g kvalitet)

---

## ğŸš€ Snabbstart

### 1. Installation

```powershell
# GÃ¥ till projektmappen
cd "C:\Users\...\RAG"

# Installera dependencies
python -m pip install -r requirements.txt

# Skapa .env med OpenAI API-nyckel
echo OPENAI_API_KEY=sk-... > .env
```

### 2. Verifiera setup

```powershell
python -m rag.check
```

**FÃ¶rvÃ¤ntat:**

```
[OK] OPENAI_API_KEY loaded
[OK] config/rag_config.yaml loaded
All checks passed.
```

### 3. Indexera dokument & stÃ¤ll en frÃ¥ga

```powershell
# Skapa testmapp med ett dokument
mkdir my_docs
echo RAG-motorn stÃ¶der Q&A, sammanfattning, extraktion. > my_docs/intro.txt

# Indexera + frÃ¥ga
python -m cli.chat_cli --verbose `
  --docs_dir "./my_docs" `
  --workspace default `
  --mode answer `
  "Vad stÃ¶der RAG-motorn?"
```

**Exempeloutput:**

```json
{
  "answer": "RAG-motorn stÃ¶der Q&A, sammanfattning och extraktion.",
  "sources": [
    {
      "document_name": "intro.txt",
      "page_number": 1,
      "snippet": "RAG-motorn stÃ¶der Q&A, sammanfattning, extraktion."
    }
  ],
  "mode": "answer"
}
```

### 4. KÃ¶r igen (frÃ¥n cache, utan embeddings)

```powershell
python -m cli.chat_cli `
  --docs_dir "./my_docs" `
  --workspace default `
  --mode summary `
  "Sammanfatta systemet"
```

**Second run â†’ index laddas frÃ¥n disk-cache â†’ 0 embeddings â†’ svar â‰ˆ < 1s.**

---

## ğŸ“– AnvÃ¤ndning (CLI)

### Grundkommando

```powershell
python -m cli.chat_cli `
  --docs_dir "C:\path\to\docs" `
  --workspace production `
  --mode answer `
  "Din frÃ¥ga hÃ¤r"
```

**Flaggor:**

- `--docs_dir` â€“ Mapp med .txt / .md / .pdf / .docx
- `--workspace` â€“ Workspace-id (multi-tenant)
- `--mode` â€“ `answer` | `summary` | `extract`
- `--doc_ids` â€“ Filtrera pÃ¥ specifika dokument (kommaseparerade filnamn)
- `--verbose` â€“ Aktivera debug (BM25/emb/hybrid-score per chunk)

### Filtrera pÃ¥ specifika dokument

```powershell
python -m cli.chat_cli `
  --docs_dir "./docs" `
  --workspace default `
  --doc_ids intro.txt,policy.md `
  --mode answer `
  "Vad Ã¤r betalningsvillkoren?"
```

### Debug-lÃ¤ge

```powershell
python -m cli.chat_cli --verbose `
  --docs_dir "./docs" `
  --workspace default `
  --mode answer `
  "TestfrÃ¥ga"
```

**Exempel pÃ¥ debugrad:**

```
[cli] Indexed files: 5, chunks: 23, vectors: 23
[retriever] chunk_14 | bm25=0.723 | emb=0.841 | hybrid=0.804 | preview='...'
```

---

## ğŸŒ Frontend Integration

**API Ã¤r redo fÃ¶r frontend-integration!**

### Quick Start

1. **Starta API-servern:**
```powershell
python -m uvicorn api.main:app --reload --host 127.0.0.1 --port 8000
```

2. **Swagger UI:** Ã–ppna `http://localhost:8000/docs` fÃ¶r interaktiv API-dokumentation

3. **Testa API:**
```powershell
# Health check
curl http://localhost:8000/health

# Query
curl -X POST http://localhost:8000/query `
  -H "Content-Type: application/json" `
  -d '{\"query\": \"Vad stÃ¶der RAG-motorn?\", \"workspace\": \"default\"}'
```

### Dokumentation

- **[Frontend Integration Guide](docs/FRONTEND_INTEGRATION.md)** â€“ Komplett guide med TypeScript-typer, React/Vue/Svelte-exempel
- **[API Reference](docs/API_REFERENCE.md)** â€“ Detaljerad API-dokumentation
- **TypeScript Types** â€“ Se `frontend/types/rag-api.ts`
- **API Client** â€“ Se `frontend/lib/rag-client.ts`
- **React Example** â€“ Se `frontend/examples/react-example.tsx`

### Endpoints

- `GET /health` â€“ Health check
- `POST /query` â€“ StÃ¤ll frÃ¥gor till RAG-motorn
- `GET /docs` â€“ Swagger UI (interaktiv dokumentation)

---

## ğŸ§ª Testing

### 1. Golden Evaluation (kvalitet)

```powershell
python -m evaluation.golden_eval
```

**Exempeloutput:**

```
========== RAG GOLDEN EVAL ==========
Antal testfall: 3
Source-hit rate:          1.000
Genomsnittlig recall:     1.000
Genomsnittlig must-cover: 0.667
Genomsnittlig nice-cover: 0.250
Totala forbidden-hits:    0
Tier-fÃ¶rdelning:
  Diamond  : 1/3
  Silver   : 1/3
  Bronze   : 1/3
=====================================
```

**LÃ¤gg till egna golden-cases:**

```jsonl
# evaluation/data/rag_golden.jsonl
{"id": "test1", "query": "Din frÃ¥ga?", "must_have_keywords": ["svar", "korrekt"]}
```

Varje rad Ã¤r ett JSON-objekt med t.ex.:

- `id`, `query`, `workspace`, `doc_ids`
- `expected_sources`
- `must_have_keywords`, `nice_to_have_keywords`, `forbidden_keywords`
- `difficulty`, `tags`

### 2. Performance Test (latens)

```powershell
# 100 requests mot golden-queries
python -m evaluation.perf_eval --runs 100
```

**Exempeloutput:**

```
========== RAG PERFORMANCE ==========
Antal mÃ¤tta requests: 100
Medel-latens:   1243.0 ms
p50-latens:     1140.9 ms
p95-latens:     1692.5 ms
p99-latens:     2135.2 ms
Max-latens:     2176.8 ms
=====================================
[PASS] p95 latency inom trÃ¶skeln 2000ms
[FAIL] Medel-latens Ã¶ver trÃ¶skeln 1000ms
```

### 3. Stress Test (robusthet)

```powershell
# 500 requests
python -m evaluation.perf_eval --runs 500
```

---

## âš™ï¸ Konfiguration

### `config/rag_config.yaml`

**Modeller:**

```yaml
models:
  embeddings: text-embedding-3-large
  llm:
    answer: gpt-4o
    answer_premium: gpt-4.1
    summary: gpt-4o-mini
    extract: gpt-4o-mini
```

**Retrieval:**

```yaml
retrieval:
  mode: hybrid   # hybrid | bm25 | embeddings
  top_k: 8
  hybrid:
    alpha: 0.35   # BM25-vikt
    beta: 0.65    # Embeddings-vikt
```

**Chunking:**

```yaml
chunking:
  target_tokens: 600
  overlap_tokens: 120
```

**Cache:**

```yaml
storage:
  index_dir: ./index_cache
```

---

## ğŸ—ï¸ Arkitektur

### FlÃ¶de

```
Dokument
  â†“
Text Extraction (TXT/MD/PDF/DOCX)
  â†“
Chunking (600 tokens, 120 overlap)
  â†“
Embeddings (OpenAI)
  â†“
Index (numpy + BM25) â†’ Disk-cache (MTIME)
  â†“
FrÃ¥ga
  â†“
Query Embedding + BM25 â†’ Hybrid Retrieval (BM25 + Embeddings)
  â†“
Top-K chunks
  â†“
LLM (GPT-4o / 4o-mini)
  â†“
Svar + KÃ¤llhÃ¤nvisningar
```

### Filstruktur (fÃ¶renklad)

```
RAG/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ rag_config.yaml          # Modeller, chunking, retrieval, cache
â”œâ”€â”€ rag/
â”‚   â”œâ”€â”€ embeddings_client.py     # OpenAI embeddings
â”‚   â”œâ”€â”€ llm_client.py            # GPT-4o/4o-mini
â”‚   â”œâ”€â”€ index.py                 # InMemoryIndex (numpy)
â”‚   â”œâ”€â”€ index_store.py           # Disk-cache (MTIME-guards)
â”‚   â”œâ”€â”€ retriever.py             # Hybrid (BM25 + embeddings)
â”‚   â”œâ”€â”€ engine.py                # RAG-orkestrering
â”‚   â””â”€â”€ store.py                 # SQLite persistens
â”œâ”€â”€ ingest/
â”‚   â”œâ”€â”€ text_extractor.py        # TXT/MD/PDF/DOCX
â”‚   â””â”€â”€ chunker.py               # Chunking med overlap
â”œâ”€â”€ cli/
â”‚   â””â”€â”€ chat_cli.py              # CLI
â”œâ”€â”€ evaluation/
â”‚   â”œâ”€â”€ golden_eval.py           # Kvalitet (tier-system)
â”‚   â”œâ”€â”€ perf_eval.py             # Latens & stress
â”‚   â””â”€â”€ data/
â”‚       â””â”€â”€ rag_golden.jsonl     # Golden-cases
â””â”€â”€ .env                         # OPENAI_API_KEY
```

---

## ğŸ“Š Metrics & Quality Gates

### Golden Evaluation â€“ tier-system

- **Diamond**: recall â‰¥ 0.90, must â‰¥ 0.95, nice â‰¥ 0.70, 0 forbidden
- **Platinum**: recall â‰¥ 0.80, must â‰¥ 0.90, nice â‰¥ 0.50, 0 forbidden
- **Gold**: recall â‰¥ 0.70, must â‰¥ 0.85, nice â‰¥ 0.30, 0 forbidden
- **Silver**: source_hit & must â‰¥ 0.70, 0 forbidden
- **Bronze**: allt annat

**Nyckelmetriker:**

- `source_hit_rate` â€“ TrÃ¤ffar rÃ¤tt dokument?
- `source_recall` â€“ Hur mÃ¥nga expected sources hÃ¤mtas?
- `must_coverage` â€“ Andel must-keywords som finns i svaret
- `nice_coverage` â€“ Andel nice-keywords i svaret
- `forbidden_hits` â€“ Borde vara 0 (annars hÃ¥rt rÃ¶tt kort)

### Performance â€“ latens

- **p50** â€“ Median
- **p95** â€“ 95% av requests under detta vÃ¤rde
- **p99** â€“ Extrem-svans
- **max** â€“ LÃ¥ngsammaste request

**Standardgates (kan justeras):**

- p95 â‰¤ 2000 ms
- avg â‰¤ 1000 ms

**Exit code:**

- `0` = alla gates passerade
- `1` = minst en gate failade â†’ kan blocka deploy i CI

---

## ğŸ”§ Troubleshooting

### `ModuleNotFoundError: No module named 'rag'`

**KÃ¶r alltid frÃ¥n projektroten:**

```powershell
cd "C:\...\RAG"
python -m cli.chat_cli ...
```

### `Missing OPENAI_API_KEY`

**Se till att .env finns i projektroten:**

```powershell
echo OPENAI_API_KEY=sk-your-key > .env
python -m rag.check
```

### Indexerar 0 filer

**Kolla sÃ¶kvÃ¤g och filformat:**

```powershell
Test-Path "./my_docs"
Get-ChildItem "./my_docs" -Include *.txt,*.md,*.pdf,*.docx
```

---

## ğŸ¯ Roadmap

### Kort sikt

- [ ] Bygga ut golden-filen till 50+ testfall
- [ ] SÃ¤tta upp CI/CD med quality gates (golden + performance)
- [ ] A/B-testa olika prompts och LLM-modeller

### MedellÃ¥ng sikt

- [x] HTTP API (FastAPI) âœ…
- [ ] Frontend (React/Svelte eller liknande) â€“ Integration-guide klar
- [ ] Multi-user auth & separata workspaces
- [ ] Alternativa index-backends (Chroma/Faiss/pgvector)

### LÃ¥ng sikt

- [x] Cross-encoder re-ranker âœ…
- [ ] Multimodal RAG (bilder, tabeller, bilagor)
- [ ] Real-time indexering (webhooks / event-drivet)
- [ ] Dashboard fÃ¶r metrics & analytics

---

## ğŸ“š Dependencies

**Core:**

- `openai` â€“ Embeddings & LLM
- `numpy` â€“ Vektoroperationer
- `rank-bm25` â€“ BM25-sÃ¶kning

**Ingest:**

- `pypdf` â€“ PDF-extraktion
- `python-docx` â€“ DOCX-extraktion

**Config:**

- `pyyaml` â€“ YAML-konfiguration
- `python-dotenv` â€“ .env-hantering

Se Ã¤ven `requirements.txt` fÃ¶r full lista.

---

## ğŸ“ Licens

MIT License â€“ se LICENSE fÃ¶r detaljer.

---

## ğŸ¤ Bidra

1. Forka projektet
2. Skapa feature-branch: `git checkout -b feature/amazing`
3. Commit:a Ã¤ndringar: `git commit -m "Add amazing feature"`
4. Push:a: `git push origin feature/amazing`
5. Ã–ppna en Pull Request

---

## ğŸ“§ Kontakt

- Ã–ppna ett issue fÃ¶r buggar/frÃ¥gor
- FÃ¶r enterprise/anpassningar: kontakta oss via e-post

---

**Built with â¤ï¸ for Swedish AI applications**
